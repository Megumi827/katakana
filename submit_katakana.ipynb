{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カタカナ15文字を自動識別するモデルの構築\n",
    "# 課題投稿用Notebook\n",
    "* これは課題投稿用ファイルです。\n",
    "* このsubmit_katakana.ipynbファイルを編集し、学習済みモデルなどの必要ファイルを同じフォルダにおき、そのフォルダをzipしたものを投稿してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import glob\n",
    "import os,sys\n",
    "import util\n",
    "from common.optimizer import Adam\n",
    "from collections import OrderedDict\n",
    "from common.layers16 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0003726861170222264 1.0\n",
      "1\n",
      "0.007116351414542419 0.998\n",
      "2\n",
      "1.8818804558404629e-07 1.0\n",
      "3\n",
      "0.00010360550890811168 1.0\n",
      "4\n",
      "0.0031616409469911234 0.998\n",
      "5\n",
      "0.0005455819206106982 1.0\n",
      "Test loss: 0.0018833423493533606\n",
      "Test accuracy: 0.9993333333333333\n"
     ]
    }
   ],
   "source": [
    "def makedataset():\n",
    "    \"\"\"\n",
    "    データセットをつくる関数です。\n",
    "    自由に編集してください。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 次の行は変更しないこと\n",
    "    test_data= util.loaddata()\n",
    "    \n",
    "    # 以下は自由に編集しても構いません\n",
    "    # 必要な前処理をここに記述してください  \n",
    "    \n",
    "    # 正規化\n",
    "    #test_data = (test_data - test_data.min()) / test_data.max()\n",
    "    #test_data = test_data.astype('float32')\n",
    "    test_data = test_data / test_data.max()\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    # 配列形式変更\n",
    "    test_data = test_data.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def func_predict(test_data, test_label):\n",
    "    \"\"\"\n",
    "    予測する関数\n",
    "    data : 画像データ\n",
    "    return loss, accuracy\n",
    "    引数とreturn以外は、自由に編集してください    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 以下を自由に編集してください\n",
    "    with open(\"katakana_model_params.pickle\", \"rb\") as f:\n",
    "        model_params = pickle.load(f)\n",
    "        \n",
    "    with open(\"katakana_model_moving_save.pickle\", \"rb\") as f:\n",
    "        model_moving = pickle.load(f)\n",
    "    \n",
    "    class BatchNormalization:\n",
    "        def __init__(self, gamma, beta, rho=0.9, moving_mean=None, moving_var=None):\n",
    "            self.gamma = gamma # スケールさせるためのパラメータ, 学習によって更新させる.\n",
    "            self.beta = beta # シフトさせるためのパラメータ, 学習によって更新させる\n",
    "            self.rho = rho # 移動平均を算出する際に使用する減衰率\n",
    "\n",
    "            # 予測時に使用する平均と分散\n",
    "            self.moving_mean = moving_mean # muの移動平均\n",
    "            self.moving_var = moving_var        # varの移動平均\n",
    "\n",
    "            # 計算中に算出される値を保持しておく変数群\n",
    "            self.batch_size = None\n",
    "            self.x_mu = None\n",
    "            self.x_std = None        \n",
    "            self.std = None\n",
    "            self.dgamma = None\n",
    "            self.dbeta = None\n",
    "\n",
    "        def forward(self, x, train_flg=True):\n",
    "            \"\"\"\n",
    "            順伝播計算\n",
    "            x :  Conv層の場合は4次元、全結合層の場合は2次元  \n",
    "            \"\"\"\n",
    "            if x.ndim == 4:\n",
    "                \"\"\"\n",
    "                画像形式の場合\n",
    "                \"\"\"\n",
    "                N, C, H, W = x.shape\n",
    "                x = x.transpose(0, 2, 3, 1) # NHWCに入れ替え\n",
    "                x = x.reshape(N*H*W, C) # (N*H*W,C)の2次元配列に変換\n",
    "                out = self.__forward(x, train_flg)\n",
    "                out = out.reshape(N, H, W, C)# 4次元配列に変換\n",
    "                out = out.transpose(0, 3, 1, 2) # 軸をNCHWに入れ替え\n",
    "            elif x.ndim == 2:\n",
    "                \"\"\"\n",
    "                画像形式以外の場合\n",
    "                \"\"\"\n",
    "                out = self.__forward(x, train_flg)           \n",
    "\n",
    "            return out\n",
    "\n",
    "        def __forward(self, x, train_flg, epsilon=1e-8):\n",
    "            \"\"\"\n",
    "            x : 入力. n×dの行列. nはあるミニバッチのバッチサイズ. dは手前の層のノード数\n",
    "            \"\"\"\n",
    "            #if (self.moving_mean is None) or (self.moving_var is None):\n",
    "            #    N, D = x.shape\n",
    "            #    self.moving_mean = np.zeros(D)\n",
    "            #    self.moving_var = np.zeros(D)\n",
    "\n",
    "            x_mu = x - self.moving_mean # n*d行列\n",
    "            x_std = x_mu / np.sqrt(self.moving_var + epsilon) # n*d行列\n",
    "\n",
    "            # gammaでスケールし、betaでシフトさせる\n",
    "            out = self.gamma * x_std + self.beta # n*d行列\n",
    "            return out\n",
    "\n",
    "        def backward(self, dout):\n",
    "            \"\"\"\n",
    "            逆伝播計算\n",
    "            dout : Conv層の場合は4次元、全結合層の場合は2次元  \n",
    "            \"\"\"\n",
    "            if dout.ndim == 4:\n",
    "                \"\"\"\n",
    "                画像形式の場合\n",
    "                \"\"\"            \n",
    "                N, C, H, W = dout.shape\n",
    "                dout = dout.transpose(0, 2, 3, 1) # NHWCに入れ替え\n",
    "                dout = dout.reshape(N*H*W, C) # (N*H*W,C)の2次元配列に変換\n",
    "                dx = self.__backward(dout)\n",
    "                dx = dx.reshape(N, H, W, C)# 4次元配列に変換\n",
    "                dx = dx.transpose(0, 3, 1, 2) # 軸をNCHWに入れ替え\n",
    "            elif dout.ndim == 2:\n",
    "                \"\"\"\n",
    "                画像形式以外の場合\n",
    "                \"\"\"\n",
    "                dx = self.__backward(dout)\n",
    "\n",
    "            return dx\n",
    "\n",
    "        def __backward(self, dout):\n",
    "\n",
    "            \"\"\"\n",
    "            ここを完成させるには、計算グラフを理解する必要があり、実装にかなり時間がかかる.\n",
    "            よって、この関数を完成させる作業は、宿題とする.\n",
    "            \"\"\"\n",
    "\n",
    "            # betaの勾配\n",
    "            dbeta = dout.sum(axis=0)\n",
    "\n",
    "            # gammaの勾配(n方向に合計)\n",
    "            dgamma = np.sum(self.x_std * dout, axis=0)\n",
    "\n",
    "            # Xstdの勾配\n",
    "            a1 = self.gamma * dout\n",
    "\n",
    "            # Xmuの勾配\n",
    "            a2 = a1 / self.std\n",
    "\n",
    "            # 標準偏差の逆数の勾配(n方向に合計)\n",
    "            a3 = a1 * self.x_mu \n",
    "\n",
    "            # 標準偏差の勾配\n",
    "            a4 = -(np.sum(a3, axis=0) ) / (self.std * self.std)\n",
    "\n",
    "            # 分散の勾配\n",
    "            a5 = 0.5 * a4 / self.std\n",
    "\n",
    "            # Xmuの2乗の勾配\n",
    "            a6 = a5 / self.batch_size\n",
    "\n",
    "            # Xmuの勾配\n",
    "            a7 = 2.0  * self.x_mu * a6\n",
    "\n",
    "            # muの勾配\n",
    "            a8 = -(a2+a7)\n",
    "\n",
    "            # Xの勾配\n",
    "            dx = a2 + a7 +  np.sum(a8, axis=0) / self.batch_size # 第3項はn方向に平均\n",
    "\n",
    "            self.dgamma = dgamma\n",
    "            self.dbeta = dbeta\n",
    "\n",
    "            return dx\n",
    "    \n",
    "    class SimpleConvNet:\n",
    "        def __init__(self, input_dim1=(1, 28, 28),input_dim2=(32, 12, 12),\n",
    "                     conv_param={'filter_num':32, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                     pool_param={'pool_size':2, 'pad':0, 'stride':2},\n",
    "                     hidden_size=500, output_size=15, weight_init_std=0.01):\n",
    "            \"\"\"\n",
    "            input_size : tuple, 入力の配列形状(チャンネル数、画像の高さ、画像の幅)\n",
    "            conv_param : dict, 畳み込みの条件\n",
    "            pool_param : dict, プーリングの条件\n",
    "            hidden_size : int, 隠れ層のノード数\n",
    "            output_size : int, 出力層のノード数\n",
    "            weight_init_std ： float, 重みWを初期化する際に用いる標準偏差\n",
    "            \"\"\"\n",
    "\n",
    "            filter_num = conv_param['filter_num']\n",
    "            filter_size = conv_param['filter_size']\n",
    "            filter_pad = conv_param['pad']\n",
    "            filter_stride = conv_param['stride']\n",
    "\n",
    "            pool_size = pool_param['pool_size']\n",
    "            pool_pad = pool_param['pad']\n",
    "            pool_stride = pool_param['stride']\n",
    "\n",
    "            input_size1 = input_dim1[1]\n",
    "            input_size2 = input_dim2[1]\n",
    "            conv_output_size1 = (input_size1 + 2*filter_pad - filter_size) // filter_stride + 1 # 畳み込み後のサイズ(H,W共通)\n",
    "            pool_output_size1 = (conv_output_size1 + 2*pool_pad - pool_size) // pool_stride + 1 # プーリング後のサイズ(H,W共通)\n",
    "            pool_output_pixel1 = filter_num * pool_output_size1 * pool_output_size1 # プーリング後のピクセル総数\n",
    "\n",
    "            conv_output_size2 = (input_size2 + 2*filter_pad - filter_size) // filter_stride + 1 # 畳み込み後のサイズ(H,W共通)\n",
    "            pool_output_size2 = (conv_output_size2 + 2*pool_pad - pool_size) // pool_stride + 1 # プーリング後のサイズ(H,W共通)\n",
    "            pool_output_pixel2 = filter_num * pool_output_size2 * pool_output_size2 # プーリング後のピクセル総数\n",
    "\n",
    "\n",
    "            # 重みの初期化\n",
    "            self.params = {}\n",
    "            std = weight_init_std\n",
    "            self.params['W1']=model_params['W1']\n",
    "            self.params['b1']=model_params['b1']\n",
    "            self.params['W2']=model_params['W2']\n",
    "            self.params['b2']=model_params['b2']\n",
    "            self.params['W3']=model_params['W3']\n",
    "            self.params['b3']=model_params['b3']\n",
    "            self.params['W4']=model_params['W4']\n",
    "            self.params['b4']=model_params['b4']\n",
    "            self.params['gamma1'] = 1\n",
    "            self.params['beta1'] = 0\n",
    "            self.params['gamma2'] = 1\n",
    "            self.params['beta2'] = 0\n",
    "\n",
    "\n",
    "            # レイヤの生成\n",
    "            self.layers = OrderedDict()\n",
    "            self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                               conv_param['stride'], conv_param['pad'])\n",
    "            self.layers['BatchNormalization1'] = BatchNormalization(self.params['gamma1'], self.params['beta1'], rho=0.9, moving_mean=model_moving['moving_mean1'], moving_var=model_moving['moving_var1'])\n",
    "            self.layers['ReLU1'] = ReLU()\n",
    "            self.layers['Pool1'] = MaxPooling(pool_h=pool_size, pool_w=pool_size, stride=pool_stride, pad=pool_pad)\n",
    "\n",
    "            self.layers['Conv2'] = Convolution(self.params['W4'], self.params['b4'],\n",
    "                                               conv_param['stride'], conv_param['pad'])\n",
    "            self.layers['BatchNormalization2'] = BatchNormalization(self.params['gamma2'], self.params['beta2'], rho=0.9, moving_mean=model_moving['moving_mean2'], moving_var=model_moving['moving_var2'])\n",
    "            self.layers['ReLU3'] = ReLU()\n",
    "            self.layers['Pool2'] = MaxPooling(pool_h=pool_size, pool_w=pool_size, stride=pool_stride, pad=pool_pad)\n",
    "\n",
    "            #self.layers['Dropout1'] = Dropout(dropout_ratio=0.3)\n",
    "            self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "            self.layers['ReLU2'] = ReLU()\n",
    "            #self.layers['Dropout2'] = Dropout(dropout_ratio=0.3)\n",
    "            self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "            self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "            #self.moving = {}\n",
    "            #self.moving['moving_mean1'] = self.layers['BatchNormalization1'].moving_mean\n",
    "            #self.moving['moving_var1'] = self.layers['BatchNormalization1'].moving_var\n",
    "            #self.moving['moving_mean2'] = self.layers['BatchNormalization2'].moving_mean\n",
    "            #self.moving['moving_var2'] = self.layers['BatchNormalization2'].moving_var\n",
    "\n",
    "        def predict(self, x):\n",
    "            for layer in self.layers.values():\n",
    "                x = layer.forward(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        def loss(self, x, t):\n",
    "            \"\"\"\n",
    "            損失関数\n",
    "            x : 入力データ\n",
    "            t : 教師データ\n",
    "            \"\"\"\n",
    "            y = self.predict(x)\n",
    "            return self.last_layer.forward(y, t)\n",
    "\n",
    "        def accuracy(self, x, t, batch_size=100):\n",
    "            if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "            acc = 0.0\n",
    "\n",
    "            for i in range(int(x.shape[0] / batch_size)):\n",
    "                tx = x[i*batch_size:(i+1)*batch_size]\n",
    "                tt = t[i*batch_size:(i+1)*batch_size]\n",
    "                y = self.predict(tx)\n",
    "                y = np.argmax(y, axis=1)\n",
    "                acc += np.sum(y == tt) \n",
    "\n",
    "            return acc / x.shape[0]\n",
    "\n",
    "        def gradient(self, x, t):\n",
    "            \"\"\"勾配を求める（誤差逆伝播法）\n",
    "            Parameters\n",
    "            ----------\n",
    "            x : 入力データ\n",
    "            t : 教師データ\n",
    "            Returns\n",
    "            -------\n",
    "            各層の勾配を持ったディクショナリ変数\n",
    "                grads['W1']、grads['W2']、...は各層の重み\n",
    "                grads['b1']、grads['b2']、...は各層のバイアス\n",
    "            \"\"\"\n",
    "            # forward\n",
    "            self.loss(x, t)\n",
    "\n",
    "            # backward\n",
    "            dout = 1\n",
    "            dout = self.last_layer.backward(dout)\n",
    "\n",
    "            layers = list(self.layers.values())\n",
    "            layers.reverse()\n",
    "            for layer in layers:\n",
    "                dout = layer.backward(dout)\n",
    "\n",
    "            # 設定\n",
    "            grads = {}\n",
    "            grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "            grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "            grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "            grads['W4'], grads['b4'] = self.layers['Conv2'].dW, self.layers['Conv2'].db\n",
    "            grads['gamma1'] = self.layers['BatchNormalization1'].dgamma\n",
    "            grads['beta1'] = self.layers['BatchNormalization1'].dbeta\n",
    "            grads['gamma2'] = self.layers['BatchNormalization2'].dgamma\n",
    "            grads['beta2'] = self.layers['BatchNormalization2'].dbeta\n",
    "\n",
    "\n",
    "\n",
    "            return grads\n",
    "\n",
    "    \n",
    "    snet = SimpleConvNet(input_dim1=(1, 28, 28), input_dim2=(32, 12, 12),\n",
    "                     conv_param={'filter_num':32, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                     pool_param={'pool_size':2, 'pad':0, 'stride':2},\n",
    "                     hidden_size=500, output_size=15, weight_init_std=0.01)\n",
    "    \n",
    "    accuracy = snet.accuracy(test_data, test_label)\n",
    "    loss  = snet.loss(test_data, test_label)\n",
    "    \n",
    "    return loss, accuracy # 編集不可\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    編集しないでください。\n",
    "    \"\"\"\n",
    "    # テスト用データをつくる\n",
    "    test_data = makedataset()\n",
    "\n",
    "    # 予測し精度を算出する\n",
    "    util.accuracy(func_predict, test_data)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
